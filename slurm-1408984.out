/var/spool/slurmd/job1408984/slurm_script: line 7: vbd667: command not found
1
Tue Apr 21 13:11:12 2020       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  TITAN Xp            Off  | 00000000:02:00.0 Off |                  N/A |
| 26%   44C    P0    61W / 250W |      0MiB / 12196MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  GeForce GTX 1080    Off  | 00000000:03:00.0 Off |                  N/A |
| 17%   45C    P0    45W / 198W |      0MiB /  8119MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  GeForce GTX 1080    Off  | 00000000:83:00.0 Off |                  N/A |
|  0%   42C    P0    39W / 198W |      0MiB /  8119MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  GeForce GTX 1080    Off  | 00000000:84:00.0 Off |                  N/A |
| 20%   45C    P0    38W / 198W |      0MiB /  8119MiB |      2%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
/var/spool/slurmd/job1408984/slurm_script: line 10: activate: No such file or directory
2020-04-21 13:11:15.289654: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory
2020-04-21 13:11:15.289794: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory
2020-04-21 13:11:15.289813: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-04-21 14:08:18.232051: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-04-21 14:08:20.059437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: GeForce GTX 1080 computeCapability: 6.1
coreClock: 1.8095GHz coreCount: 20 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 298.32GiB/s
2020-04-21 14:08:20.063591: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-21 14:08:20.075347: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-21 14:08:20.082932: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-21 14:08:20.093962: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-21 14:08:20.103753: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-21 14:08:20.105895: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-21 14:08:20.111381: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-21 14:08:20.112648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-21 14:08:20.122863: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2400025000 Hz
2020-04-21 14:08:20.123155: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5619fdd16e50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-04-21 14:08:20.123180: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-04-21 14:08:20.238151: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561a04961dd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-04-21 14:08:20.238215: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080, Compute Capability 6.1
2020-04-21 14:08:20.239113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: GeForce GTX 1080 computeCapability: 6.1
coreClock: 1.8095GHz coreCount: 20 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 298.32GiB/s
2020-04-21 14:08:20.239205: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-21 14:08:20.239241: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-21 14:08:20.239271: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-21 14:08:20.239302: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-21 14:08:20.239332: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-21 14:08:20.239363: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-21 14:08:20.239395: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-21 14:08:20.240530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-21 14:08:20.240580: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-21 14:08:20.242220: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-21 14:08:20.242241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-04-21 14:08:20.242254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-04-21 14:08:20.243485: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7605 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:03:00.0, compute capability: 6.1)
2020-04-21 14:08:32.563582: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-21 14:08:32.880039: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
Currently train set is: MR
[LABEL] 2  labels: {'0', '1'}
word_index: 18574
Total 400003 word vectors.
[train] Shape of data tensor: (10662, 90)
[train] Shape of label tensor: (10662, 2)
[search time]: 0 / 30
[paras]: modelcnn_hidden_unit_num200_dropout_rate0.3_lr0.0006_batch_size96_val_split0.15_layers2_n_head8_d_inner_hid256_roles['positional', 'both_direct', 'stop_word', 'POS']_
lenth of train_Test: 1
==not gah model == True cnn
 lenth of the first x_Train:  10662
Train on 9062 samples, validate on 1600 samples
Epoch 1/30

  96/9062 [..............................] - ETA: 4:41 - loss: 0.6992 - acc: 0.6771
 672/9062 [=>............................] - ETA: 38s - loss: 0.7356 - acc: 0.5729 
1248/9062 [===>..........................] - ETA: 19s - loss: 0.7325 - acc: 0.5681
1824/9062 [=====>........................] - ETA: 12s - loss: 0.7274 - acc: 0.5669
2400/9062 [======>.......................] - ETA: 8s - loss: 0.7142 - acc: 0.5817 
2976/9062 [========>.....................] - ETA: 6s - loss: 0.6994 - acc: 0.5927
3552/9062 [==========>...................] - ETA: 5s - loss: 0.6971 - acc: 0.5898
4128/9062 [============>.................] - ETA: 4s - loss: 0.6916 - acc: 0.5921
4704/9062 [==============>...............] - ETA: 3s - loss: 0.6881 - acc: 0.5976
5280/9062 [================>.............] - ETA: 2s - loss: 0.6870 - acc: 0.5975
5856/9062 [==================>...........] - ETA: 1s - loss: 0.6828 - acc: 0.6013
6432/9062 [====================>.........] - ETA: 1s - loss: 0.6844 - acc: 0.5992
7008/9062 [======================>.......] - ETA: 1s - loss: 0.6833 - acc: 0.5996
7584/9062 [========================>.....] - ETA: 0s - loss: 0.6771 - acc: 0.6042
8160/9062 [==========================>...] - ETA: 0s - loss: 0.6747 - acc: 0.6066
8736/9062 [===========================>..] - ETA: 0s - loss: 0.6703 - acc: 0.6116
9062/9062 [==============================] - 5s 543us/step - loss: 0.6677 - acc: 0.6134 - val_loss: 0.4959 - val_acc: 0.8031
Epoch 2/30

  96/9062 [..............................] - ETA: 0s - loss: 0.5695 - acc: 0.7500
 672/9062 [=>............................] - ETA: 0s - loss: 0.5778 - acc: 0.7039
1248/9062 [===>..........................] - ETA: 0s - loss: 0.5671 - acc: 0.7155
1824/9062 [=====>........................] - ETA: 0s - loss: 0.5582 - acc: 0.7253
2400/9062 [======>.......................] - ETA: 0s - loss: 0.5605 - acc: 0.7221
2976/9062 [========>.....................] - ETA: 0s - loss: 0.5528 - acc: 0.7272
3552/9062 [==========>...................] - ETA: 0s - loss: 0.5509 - acc: 0.7252
4128/9062 [============>.................] - ETA: 0s - loss: 0.5546 - acc: 0.7202
4704/9062 [==============>...............] - ETA: 0s - loss: 0.5540 - acc: 0.7202
5280/9062 [================>.............] - ETA: 0s - loss: 0.5550 - acc: 0.7184
5856/9062 [==================>...........] - ETA: 0s - loss: 0.5588 - acc: 0.7153
6432/9062 [====================>.........] - ETA: 0s - loss: 0.5551 - acc: 0.7183
7008/9062 [======================>.......] - ETA: 0s - loss: 0.5550 - acc: 0.7183
7584/9062 [========================>.....] - ETA: 0s - loss: 0.5539 - acc: 0.7178
8256/9062 [==========================>...] - ETA: 0s - loss: 0.5513 - acc: 0.7192
8832/9062 [============================>.] - ETA: 0s - loss: 0.5489 - acc: 0.7207
9062/9062 [==============================] - 1s 96us/step - loss: 0.5474 - acc: 0.7214 - val_loss: 0.7754 - val_acc: 0.5119
Epoch 3/30

  96/9062 [..............................] - ETA: 0s - loss: 0.4871 - acc: 0.7604
 672/9062 [=>............................] - ETA: 0s - loss: 0.5043 - acc: 0.7634
1248/9062 [===>..........................] - ETA: 0s - loss: 0.5057 - acc: 0.7548
1824/9062 [=====>........................] - ETA: 0s - loss: 0.5010 - acc: 0.7560
2400/9062 [======>.......................] - ETA: 0s - loss: 0.4990 - acc: 0.7571
2976/9062 [========>.....................] - ETA: 0s - loss: 0.4961 - acc: 0.7618
3552/9062 [==========>...................] - ETA: 0s - loss: 0.4948 - acc: 0.7646
4032/9062 [============>.................] - ETA: 0s - loss: 0.4903 - acc: 0.7656
4608/9062 [==============>...............] - ETA: 0s - loss: 0.4896 - acc: 0.7637
5184/9062 [================>.............] - ETA: 0s - loss: 0.4880 - acc: 0.7654
5760/9062 [==================>...........] - ETA: 0s - loss: 0.4865 - acc: 0.7667
6336/9062 [===================>..........] - ETA: 0s - loss: 0.4841 - acc: 0.7705
6912/9062 [=====================>........] - ETA: 0s - loss: 0.4848 - acc: 0.7701
7488/9062 [=======================>......] - ETA: 0s - loss: 0.4868 - acc: 0.7690
8064/9062 [=========================>....] - ETA: 0s - loss: 0.4867 - acc: 0.7688
8640/9062 [===========================>..] - ETA: 0s - loss: 0.4828 - acc: 0.7712
9062/9062 [==============================] - 1s 97us/step - loss: 0.4822 - acc: 0.7716 - val_loss: 0.6917 - val_acc: 0.6106
Epoch 4/30

  96/9062 [..............................] - ETA: 0s - loss: 0.4754 - acc: 0.7604
 672/9062 [=>............................] - ETA: 0s - loss: 0.4369 - acc: 0.7917
1248/9062 [===>..........................] - ETA: 0s - loss: 0.4363 - acc: 0.7893
1824/9062 [=====>........................] - ETA: 0s - loss: 0.4341 - acc: 0.7933
2400/9062 [======>.......................] - ETA: 0s - loss: 0.4352 - acc: 0.7979
2976/9062 [========>.....................] - ETA: 0s - loss: 0.4417 - acc: 0.7927
3552/9062 [==========>...................] - ETA: 0s - loss: 0.4388 - acc: 0.7936
4128/9062 [============>.................] - ETA: 0s - loss: 0.4429 - acc: 0.7912
4704/9062 [==============>...............] - ETA: 0s - loss: 0.4447 - acc: 0.7891
5280/9062 [================>.............] - ETA: 0s - loss: 0.4470 - acc: 0.7888
5856/9062 [==================>...........] - ETA: 0s - loss: 0.4459 - acc: 0.7901
6432/9062 [====================>.........] - ETA: 0s - loss: 0.4468 - acc: 0.7900
7008/9062 [======================>.......] - ETA: 0s - loss: 0.4451 - acc: 0.7897
7584/9062 [========================>.....] - ETA: 0s - loss: 0.4413 - acc: 0.7929
8160/9062 [==========================>...] - ETA: 0s - loss: 0.4377 - acc: 0.7958
8736/9062 [===========================>..] - ETA: 0s - loss: 0.4373 - acc: 0.7966
9062/9062 [==============================] - 1s 96us/step - loss: 0.4364 - acc: 0.7965 - val_loss: 0.7463 - val_acc: 0.5975
Epoch 5/30

  96/9062 [..............................] - ETA: 0s - loss: 0.3554 - acc: 0.8750
 672/9062 [=>............................] - ETA: 0s - loss: 0.3889 - acc: 0.8229
1248/9062 [===>..........................] - ETA: 0s - loss: 0.3777 - acc: 0.8341
1824/9062 [=====>........................] - ETA: 0s - loss: 0.3759 - acc: 0.8328
2400/9062 [======>.......................] - ETA: 0s - loss: 0.3701 - acc: 0.8375
2976/9062 [========>.....................] - ETA: 0s - loss: 0.3763 - acc: 0.8350
3456/9062 [==========>...................] - ETA: 0s - loss: 0.3828 - acc: 0.8307
4032/9062 [============>.................] - ETA: 0s - loss: 0.3863 - acc: 0.8299
4608/9062 [==============>...............] - ETA: 0s - loss: 0.3889 - acc: 0.8273
5184/9062 [================>.............] - ETA: 0s - loss: 0.3902 - acc: 0.8247
5760/9062 [==================>...........] - ETA: 0s - loss: 0.3933 - acc: 0.8238
6336/9062 [===================>..........] - ETA: 0s - loss: 0.3941 - acc: 0.8250
6912/9062 [=====================>........] - ETA: 0s - loss: 0.3946 - acc: 0.8244
7488/9062 [=======================>......] - ETA: 0s - loss: 0.3946 - acc: 0.8257
8064/9062 [=========================>....] - ETA: 0s - loss: 0.3927 - acc: 0.8276
8640/9062 [===========================>..] - ETA: 0s - loss: 0.3914 - acc: 0.8281
9062/9062 [==============================] - 1s 99us/step - loss: 0.3909 - acc: 0.8279 - val_loss: 0.7698 - val_acc: 0.5888
Epoch 6/30

  96/9062 [..............................] - ETA: 0s - loss: 0.3254 - acc: 0.8750
 576/9062 [>.............................] - ETA: 1s - loss: 0.3531 - acc: 0.8594
1152/9062 [==>...........................] - ETA: 1s - loss: 0.3360 - acc: 0.8646
1728/9062 [====>.........................] - ETA: 0s - loss: 0.3350 - acc: 0.8640
2304/9062 [======>.......................] - ETA: 0s - loss: 0.3320 - acc: 0.8668
2880/9062 [========>.....................] - ETA: 0s - loss: 0.3349 - acc: 0.8642
3456/9062 [==========>...................] - ETA: 0s - loss: 0.3402 - acc: 0.8637
4032/9062 [============>.................] - ETA: 0s - loss: 0.3390 - acc: 0.8619
4608/9062 [==============>...............] - ETA: 0s - loss: 0.3436 - acc: 0.8596
5184/9062 [================>.............] - ETA: 0s - loss: 0.3468 - acc: 0.8565
5760/9062 [==================>...........] - ETA: 0s - loss: 0.3472 - acc: 0.8547
6336/9062 [===================>..........] - ETA: 0s - loss: 0.3480 - acc: 0.8532
6912/9062 [=====================>........] - ETA: 0s - loss: 0.3482 - acc: 0.8523
7488/9062 [=======================>......] - ETA: 0s - loss: 0.3465 - acc: 0.8536
8064/9062 [=========================>....] - ETA: 0s - loss: 0.3490 - acc: 0.8513
8640/9062 [===========================>..] - ETA: 0s - loss: 0.3466 - acc: 0.8512
9062/9062 [==============================] - 1s 106us/step - loss: 0.3447 - acc: 0.8522 - val_loss: 0.6603 - val_acc: 0.6556
Epoch 7/30

  96/9062 [..............................] - ETA: 0s - loss: 0.2785 - acc: 0.8854
 672/9062 [=>............................] - ETA: 0s - loss: 0.2852 - acc: 0.8958
1248/9062 [===>..........................] - ETA: 0s - loss: 0.2733 - acc: 0.8958
1824/9062 [=====>........................] - ETA: 0s - loss: 0.2736 - acc: 0.8936
2400/9062 [======>.......................] - ETA: 0s - loss: 0.2756 - acc: 0.8896
2976/9062 [========>.....................] - ETA: 0s - loss: 0.2821 - acc: 0.8847
3552/9062 [==========>...................] - ETA: 0s - loss: 0.2869 - acc: 0.8815
4128/9062 [============>.................] - ETA: 0s - loss: 0.2907 - acc: 0.8796
4608/9062 [==============>...............] - ETA: 0s - loss: 0.2966 - acc: 0.8767
5184/9062 [================>.............] - ETA: 0s - loss: 0.2937 - acc: 0.8794
5760/9062 [==================>...........] - ETA: 0s - loss: 0.2911 - acc: 0.8792
6336/9062 [===================>..........] - ETA: 0s - loss: 0.2917 - acc: 0.8789
6912/9062 [=====================>........] - ETA: 0s - loss: 0.2916 - acc: 0.8789
7488/9062 [=======================>......] - ETA: 0s - loss: 0.2920 - acc: 0.8777
8064/9062 [=========================>....] - ETA: 0s - loss: 0.2925 - acc: 0.8771
8640/9062 [===========================>..] - ETA: 0s - loss: 0.2923 - acc: 0.8773
9062/9062 [==============================] - 1s 97us/step - loss: 0.2922 - acc: 0.8776 - val_loss: 0.7357 - val_acc: 0.6369
Epoch 8/30

  96/9062 [..............................] - ETA: 0s - loss: 0.2334 - acc: 0.8854
 672/9062 [=>............................] - ETA: 0s - loss: 0.2225 - acc: 0.9196
1248/9062 [===>..........................] - ETA: 0s - loss: 0.2303 - acc: 0.9175
1824/9062 [=====>........................] - ETA: 0s - loss: 0.2306 - acc: 0.9161
2400/9062 [======>.......................] - ETA: 0s - loss: 0.2368 - acc: 0.9150
2976/9062 [========>.....................] - ETA: 0s - loss: 0.2364 - acc: 0.9157
3552/9062 [==========>...................] - ETA: 0s - loss: 0.2398 - acc: 0.9127
4128/9062 [============>.................] - ETA: 0s - loss: 0.2411 - acc: 0.9109
4704/9062 [==============>...............] - ETA: 0s - loss: 0.2348 - acc: 0.9131
5280/9062 [================>.............] - ETA: 0s - loss: 0.2342 - acc: 0.9142
5856/9062 [==================>...........] - ETA: 0s - loss: 0.2361 - acc: 0.9124
6432/9062 [====================>.........] - ETA: 0s - loss: 0.2390 - acc: 0.9109
7008/9062 [======================>.......] - ETA: 0s - loss: 0.2385 - acc: 0.9108
7584/9062 [========================>.....] - ETA: 0s - loss: 0.2367 - acc: 0.9111
8160/9062 [==========================>...] - ETA: 0s - loss: 0.2379 - acc: 0.9103
8736/9062 [===========================>..] - ETA: 0s - loss: 0.2382 - acc: 0.9099
9062/9062 [==============================] - 1s 97us/step - loss: 0.2383 - acc: 0.9092 - val_loss: 0.7693 - val_acc: 0.6463
Current Model: CNN
[search time]: 1 / 30
[paras]: modelcnn_hidden_unit_num100_dropout_rate0.2_lr0.0006_batch_size96_val_split0.15_layers4_n_head4_d_inner_hid128_roles['positional', 'both_direct', 'stop_word', 'POS']_
lenth of train_Test: 1
==not gah model == True cnn
 lenth of the first x_Train:  10662
Train on 9062 samples, validate on 1600 samples
Epoch 1/30

  96/9062 [..............................] - ETA: 1:56 - loss: 0.9537 - acc: 0.5521
 768/9062 [=>............................] - ETA: 14s - loss: 0.8302 - acc: 0.5208 
1440/9062 [===>..........................] - ETA: 7s - loss: 0.7872 - acc: 0.5361 
2112/9062 [=====>........................] - ETA: 4s - loss: 0.7642 - acc: 0.5412
2784/9062 [========>.....................] - ETA: 3s - loss: 0.7422 - acc: 0.5607
3456/9062 [==========>...................] - ETA: 2s - loss: 0.7304 - acc: 0.5668
4128/9062 [============>.................] - ETA: 1s - loss: 0.7222 - acc: 0.5671
4800/9062 [==============>...............] - ETA: 1s - loss: 0.7135 - acc: 0.5763
5472/9062 [=================>............] - ETA: 1s - loss: 0.7077 - acc: 0.5789
6144/9062 [===================>..........] - ETA: 0s - loss: 0.7038 - acc: 0.5794
6816/9062 [=====================>........] - ETA: 0s - loss: 0.6958 - acc: 0.5883
7488/9062 [=======================>......] - ETA: 0s - loss: 0.6897 - acc: 0.5960
8160/9062 [==========================>...] - ETA: 0s - loss: 0.6838 - acc: 0.6007
8832/9062 [============================>.] - ETA: 0s - loss: 0.6816 - acc: 0.6019
9062/9062 [==============================] - 3s 302us/step - loss: 0.6794 - acc: 0.6042 - val_loss: 1.3062 - val_acc: 0.0594
Epoch 2/30

  96/9062 [..............................] - ETA: 0s - loss: 0.5845 - acc: 0.6562
 768/9062 [=>............................] - ETA: 0s - loss: 0.6391 - acc: 0.6393
1440/9062 [===>..........................] - ETA: 0s - loss: 0.6254 - acc: 0.6479
2112/9062 [=====>........................] - ETA: 0s - loss: 0.6192 - acc: 0.6558
2784/9062 [========>.....................] - ETA: 0s - loss: 0.6086 - acc: 0.6685
3456/9062 [==========>...................] - ETA: 0s - loss: 0.6049 - acc: 0.6748
4128/9062 [============>.................] - ETA: 0s - loss: 0.5963 - acc: 0.6827
4800/9062 [==============>...............] - ETA: 0s - loss: 0.5882 - acc: 0.6896
5472/9062 [=================>............] - ETA: 0s - loss: 0.5849 - acc: 0.6939
6144/9062 [===================>..........] - ETA: 0s - loss: 0.5829 - acc: 0.6947
6816/9062 [=====================>........] - ETA: 0s - loss: 0.5801 - acc: 0.6973
7488/9062 [=======================>......] - ETA: 0s - loss: 0.5792 - acc: 0.6967
8160/9062 [==========================>...] - ETA: 0s - loss: 0.5765 - acc: 0.6985
8832/9062 [============================>.] - ETA: 0s - loss: 0.5730 - acc: 0.7014
9062/9062 [==============================] - 1s 87us/step - loss: 0.5741 - acc: 0.7006 - val_loss: 0.7693 - val_acc: 0.5069
Epoch 3/30

  96/9062 [..............................] - ETA: 0s - loss: 0.5210 - acc: 0.7500
 768/9062 [=>............................] - ETA: 0s - loss: 0.5217 - acc: 0.7448
1440/9062 [===>..........................] - ETA: 0s - loss: 0.5223 - acc: 0.7507
2112/9062 [=====>........................] - ETA: 0s - loss: 0.5188 - acc: 0.7453
2784/9062 [========>.....................] - ETA: 0s - loss: 0.5216 - acc: 0.7432
3456/9062 [==========>...................] - ETA: 0s - loss: 0.5136 - acc: 0.7462
4128/9062 [============>.................] - ETA: 0s - loss: 0.5109 - acc: 0.7505
4704/9062 [==============>...............] - ETA: 0s - loss: 0.5099 - acc: 0.7487
5376/9062 [================>.............] - ETA: 0s - loss: 0.5126 - acc: 0.7463
6048/9062 [===================>..........] - ETA: 0s - loss: 0.5100 - acc: 0.7488
6720/9062 [=====================>........] - ETA: 0s - loss: 0.5095 - acc: 0.7503
7392/9062 [=======================>......] - ETA: 0s - loss: 0.5130 - acc: 0.7476
8064/9062 [=========================>....] - ETA: 0s - loss: 0.5128 - acc: 0.7474
8736/9062 [===========================>..] - ETA: 0s - loss: 0.5129 - acc: 0.7469
9062/9062 [==============================] - 1s 87us/step - loss: 0.5136 - acc: 0.7471 - val_loss: 0.5166 - val_acc: 0.7419
Epoch 4/30

  96/9062 [..............................] - ETA: 0s - loss: 0.3951 - acc: 0.8542
 768/9062 [=>............................] - ETA: 0s - loss: 0.4376 - acc: 0.7982
1440/9062 [===>..........................] - ETA: 0s - loss: 0.4736 - acc: 0.7632
2112/9062 [=====>........................] - ETA: 0s - loss: 0.4698 - acc: 0.7699
2784/9062 [========>.....................] - ETA: 0s - loss: 0.4655 - acc: 0.7791
3456/9062 [==========>...................] - ETA: 0s - loss: 0.4683 - acc: 0.7807
4128/9062 [============>.................] - ETA: 0s - loss: 0.4703 - acc: 0.7781
4800/9062 [==============>...............] - ETA: 0s - loss: 0.4651 - acc: 0.7815
5472/9062 [=================>............] - ETA: 0s - loss: 0.4644 - acc: 0.7809
6144/9062 [===================>..........] - ETA: 0s - loss: 0.4665 - acc: 0.7796
6720/9062 [=====================>........] - ETA: 0s - loss: 0.4640 - acc: 0.7820
7392/9062 [=======================>......] - ETA: 0s - loss: 0.4613 - acc: 0.7842
8064/9062 [=========================>....] - ETA: 0s - loss: 0.4628 - acc: 0.7820
8736/9062 [===========================>..] - ETA: 0s - loss: 0.4608 - acc: 0.7840
9062/9062 [==============================] - 1s 86us/step - loss: 0.4601 - acc: 0.7849 - val_loss: 0.8446 - val_acc: 0.5294
Epoch 5/30

  96/9062 [..............................] - ETA: 0s - loss: 0.3878 - acc: 0.8021
 768/9062 [=>............................] - ETA: 0s - loss: 0.4044 - acc: 0.8242
1440/9062 [===>..........................] - ETA: 0s - loss: 0.4109 - acc: 0.8174
2112/9062 [=====>........................] - ETA: 0s - loss: 0.4155 - acc: 0.8120
2784/9062 [========>.....................] - ETA: 0s - loss: 0.4251 - acc: 0.8046
3456/9062 [==========>...................] - ETA: 0s - loss: 0.4268 - acc: 0.8030
4128/9062 [============>.................] - ETA: 0s - loss: 0.4307 - acc: 0.8009
4800/9062 [==============>...............] - ETA: 0s - loss: 0.4311 - acc: 0.8015
5472/9062 [=================>............] - ETA: 0s - loss: 0.4307 - acc: 0.8028
6144/9062 [===================>..........] - ETA: 0s - loss: 0.4310 - acc: 0.8037
6816/9062 [=====================>........] - ETA: 0s - loss: 0.4355 - acc: 0.8005
7488/9062 [=======================>......] - ETA: 0s - loss: 0.4355 - acc: 0.7989
8160/9062 [==========================>...] - ETA: 0s - loss: 0.4344 - acc: 0.7989
8832/9062 [============================>.] - ETA: 0s - loss: 0.4347 - acc: 0.7987
9062/9062 [==============================] - 1s 86us/step - loss: 0.4323 - acc: 0.7998 - val_loss: 0.4870 - val_acc: 0.7494
Epoch 6/30

  96/9062 [..............................] - ETA: 0s - loss: 0.4838 - acc: 0.8229
 672/9062 [=>............................] - ETA: 0s - loss: 0.4044 - acc: 0.8467
1344/9062 [===>..........................] - ETA: 0s - loss: 0.3969 - acc: 0.8363
2016/9062 [=====>........................] - ETA: 0s - loss: 0.3850 - acc: 0.8393
2688/9062 [=======>......................] - ETA: 0s - loss: 0.3830 - acc: 0.8389
3360/9062 [==========>...................] - ETA: 0s - loss: 0.3860 - acc: 0.8339
4032/9062 [============>.................] - ETA: 0s - loss: 0.3926 - acc: 0.8306
4704/9062 [==============>...............] - ETA: 0s - loss: 0.3955 - acc: 0.8270
5376/9062 [================>.............] - ETA: 0s - loss: 0.3971 - acc: 0.8251
6048/9062 [===================>..........] - ETA: 0s - loss: 0.3956 - acc: 0.8261
6720/9062 [=====================>........] - ETA: 0s - loss: 0.3971 - acc: 0.8240
7392/9062 [=======================>......] - ETA: 0s - loss: 0.3945 - acc: 0.8262
8064/9062 [=========================>....] - ETA: 0s - loss: 0.3925 - acc: 0.8280
8736/9062 [===========================>..] - ETA: 0s - loss: 0.3912 - acc: 0.8294
9062/9062 [==============================] - 1s 88us/step - loss: 0.3925 - acc: 0.8284 - val_loss: 0.6361 - val_acc: 0.6675
Epoch 7/30

  96/9062 [..............................] - ETA: 0s - loss: 0.4274 - acc: 0.8125
 768/9062 [=>............................] - ETA: 0s - loss: 0.3459 - acc: 0.8581
1440/9062 [===>..........................] - ETA: 0s - loss: 0.3381 - acc: 0.8576
2112/9062 [=====>........................] - ETA: 0s - loss: 0.3347 - acc: 0.8598
2784/9062 [========>.....................] - ETA: 0s - loss: 0.3375 - acc: 0.8578
3456/9062 [==========>...................] - ETA: 0s - loss: 0.3455 - acc: 0.8553
4128/9062 [============>.................] - ETA: 0s - loss: 0.3475 - acc: 0.8544
4800/9062 [==============>...............] - ETA: 0s - loss: 0.3456 - acc: 0.8565
5472/9062 [=================>............] - ETA: 0s - loss: 0.3451 - acc: 0.8558
6144/9062 [===================>..........] - ETA: 0s - loss: 0.3474 - acc: 0.8543
6816/9062 [=====================>........] - ETA: 0s - loss: 0.3449 - acc: 0.8550
7488/9062 [=======================>......] - ETA: 0s - loss: 0.3454 - acc: 0.8539
8160/9062 [==========================>...] - ETA: 0s - loss: 0.3448 - acc: 0.8543
8832/9062 [============================>.] - ETA: 0s - loss: 0.3435 - acc: 0.8556
9062/9062 [==============================] - 1s 87us/step - loss: 0.3435 - acc: 0.8556 - val_loss: 0.6549 - val_acc: 0.6644
Epoch 8/30

  96/9062 [..............................] - ETA: 0s - loss: 0.3187 - acc: 0.8854
 768/9062 [=>............................] - ETA: 0s - loss: 0.3162 - acc: 0.8750
1440/9062 [===>..........................] - ETA: 0s - loss: 0.3070 - acc: 0.8785
2112/9062 [=====>........................] - ETA: 0s - loss: 0.3133 - acc: 0.8712
2784/9062 [========>.....................] - ETA: 0s - loss: 0.3159 - acc: 0.8678
3456/9062 [==========>...................] - ETA: 0s - loss: 0.3157 - acc: 0.8663
4128/9062 [============>.................] - ETA: 0s - loss: 0.3115 - acc: 0.8706
4800/9062 [==============>...............] - ETA: 0s - loss: 0.3087 - acc: 0.8721
5472/9062 [=================>............] - ETA: 0s - loss: 0.3066 - acc: 0.8728
6144/9062 [===================>..........] - ETA: 0s - loss: 0.3030 - acc: 0.8740
6816/9062 [=====================>........] - ETA: 0s - loss: 0.3059 - acc: 0.8722
7488/9062 [=======================>......] - ETA: 0s - loss: 0.3049 - acc: 0.8719
8160/9062 [==========================>...] - ETA: 0s - loss: 0.3044 - acc: 0.8717
8640/9062 [===========================>..] - ETA: 0s - loss: 0.3047 - acc: 0.8720
9062/9062 [==============================] - 1s 89us/step - loss: 0.3052 - acc: 0.8717 - val_loss: 0.6190 - val_acc: 0.6919
Epoch 9/30

  96/9062 [..............................] - ETA: 0s - loss: 0.1850 - acc: 0.9479
 768/9062 [=>............................] - ETA: 0s - loss: 0.2523 - acc: 0.9128
1440/9062 [===>..........................] - ETA: 0s - loss: 0.2514 - acc: 0.9111
2112/9062 [=====>........................] - ETA: 0s - loss: 0.2548 - acc: 0.9039
2784/9062 [========>.....................] - ETA: 0s - loss: 0.2561 - acc: 0.9009
3456/9062 [==========>...................] - ETA: 0s - loss: 0.2533 - acc: 0.9019
4128/9062 [============>.................] - ETA: 0s - loss: 0.2552 - acc: 0.9007
4800/9062 [==============>...............] - ETA: 0s - loss: 0.2530 - acc: 0.9006
5472/9062 [=================>............] - ETA: 0s - loss: 0.2588 - acc: 0.8966
6144/9062 [===================>..........] - ETA: 0s - loss: 0.2594 - acc: 0.8957
6816/9062 [=====================>........] - ETA: 0s - loss: 0.2641 - acc: 0.8917
7488/9062 [=======================>......] - ETA: 0s - loss: 0.2641 - acc: 0.8926
8160/9062 [==========================>...] - ETA: 0s - loss: 0.2650 - acc: 0.8926
8832/9062 [============================>.] - ETA: 0s - loss: 0.2662 - acc: 0.8927
9062/9062 [==============================] - 1s 86us/step - loss: 0.2667 - acc: 0.8922 - val_loss: 0.5456 - val_acc: 0.7375
Epoch 10/30

  96/9062 [..............................] - ETA: 0s - loss: 0.2077 - acc: 0.9271
 768/9062 [=>............................] - ETA: 0s - loss: 0.2184 - acc: 0.9219
1440/9062 [===>..........................] - ETA: 0s - loss: 0.2068 - acc: 0.9243
2112/9062 [=====>........................] - ETA: 0s - loss: 0.2078 - acc: 0.9219
2784/9062 [========>.....................] - ETA: 0s - loss: 0.2079 - acc: 0.9217
3456/9062 [==========>...................] - ETA: 0s - loss: 0.2084 - acc: 0.9210
4128/9062 [============>.................] - ETA: 0s - loss: 0.2069 - acc: 0.9205
4800/9062 [==============>...............] - ETA: 0s - loss: 0.2089 - acc: 0.9206
5472/9062 [=================>............] - ETA: 0s - loss: 0.2103 - acc: 0.9205
6144/9062 [===================>..........] - ETA: 0s - loss: 0.2129 - acc: 0.9199
6816/9062 [=====================>........] - ETA: 0s - loss: 0.2141 - acc: 0.9190
7488/9062 [=======================>......] - ETA: 0s - loss: 0.2183 - acc: 0.9164
8160/9062 [==========================>...] - ETA: 0s - loss: 0.2244 - acc: 0.9137
8832/9062 [============================>.] - ETA: 0s - loss: 0.2266 - acc: 0.9119
9062/9062 [==============================] - 1s 86us/step - loss: 0.2252 - acc: 0.9127 - val_loss: 0.6727 - val_acc: 0.7044
Epoch 11/30

  96/9062 [..............................] - ETA: 0s - loss: 0.2020 - acc: 0.9167
 768/9062 [=>............................] - ETA: 0s - loss: 0.1869 - acc: 0.9401
1440/9062 [===>..........................] - ETA: 0s - loss: 0.1774 - acc: 0.9410
2112/9062 [=====>........................] - ETA: 0s - loss: 0.1843 - acc: 0.9366
2784/9062 [========>.....................] - ETA: 0s - loss: 0.1804 - acc: 0.9379
3456/9062 [==========>...................] - ETA: 0s - loss: 0.1830 - acc: 0.9375
4128/9062 [============>.................] - ETA: 0s - loss: 0.1832 - acc: 0.9373
4800/9062 [==============>...............] - ETA: 0s - loss: 0.1845 - acc: 0.9350
5472/9062 [=================>............] - ETA: 0s - loss: 0.1827 - acc: 0.9351
6144/9062 [===================>..........] - ETA: 0s - loss: 0.1823 - acc: 0.9352
6816/9062 [=====================>........] - ETA: 0s - loss: 0.1830 - acc: 0.9340
7488/9062 [=======================>......] - ETA: 0s - loss: 0.1822 - acc: 0.9336
8160/9062 [==========================>...] - ETA: 0s - loss: 0.1850 - acc: 0.9317
8832/9062 [============================>.] - ETA: 0s - loss: 0.1863 - acc: 0.9308
9062/9062 [==============================] - 1s 87us/step - loss: 0.1870 - acc: 0.9304 - val_loss: 0.5538 - val_acc: 0.7688
Epoch 12/30

  96/9062 [..............................] - ETA: 0s - loss: 0.0901 - acc: 0.9792
 768/9062 [=>............................] - ETA: 0s - loss: 0.1531 - acc: 0.9466
1440/9062 [===>..........................] - ETA: 0s - loss: 0.1525 - acc: 0.9438
2112/9062 [=====>........................] - ETA: 0s - loss: 0.1520 - acc: 0.9437
2784/9062 [========>.....................] - ETA: 0s - loss: 0.1544 - acc: 0.9436
3456/9062 [==========>...................] - ETA: 0s - loss: 0.1549 - acc: 0.9439
4128/9062 [============>.................] - ETA: 0s - loss: 0.1571 - acc: 0.9428
4800/9062 [==============>...............] - ETA: 0s - loss: 0.1567 - acc: 0.9423
5472/9062 [=================>............] - ETA: 0s - loss: 0.1547 - acc: 0.9433
6144/9062 [===================>..........] - ETA: 0s - loss: 0.1550 - acc: 0.9430
6816/9062 [=====================>........] - ETA: 0s - loss: 0.1552 - acc: 0.9428
7488/9062 [=======================>......] - ETA: 0s - loss: 0.1555 - acc: 0.9419
8160/9062 [==========================>...] - ETA: 0s - loss: 0.1567 - acc: 0.9411
8832/9062 [============================>.] - ETA: 0s - loss: 0.1570 - acc: 0.9408
9062/9062 [==============================] - 1s 87us/step - loss: 0.1577 - acc: 0.9405 - val_loss: 0.7015 - val_acc: 0.7113
Current Model: CNN
[search time]: 2 / 30
[paras]: modeltransformer_hidden_unit_num100_dropout_rate0.2_lr0.001_batch_size96_val_split0.15_layers2_n_head4_d_inner_hid128_roles['positional', 'both_direct', 'stop_word', 'POS']_
lenth of train_Test: 1
==not gah model == True transformer
 lenth of the first x_Train:  10662
Train on 9062 samples, validate on 1600 samples
Epoch 1/30

  96/9062 [..............................] - ETA: 3:29 - loss: 0.7301 - acc: 0.6146
 288/9062 [..............................] - ETA: 1:10 - loss: 1.2669 - acc: 0.4861
 480/9062 [>.............................] - ETA: 42s - loss: 1.1313 - acc: 0.5354 
 672/9062 [=>............................] - ETA: 30s - loss: 1.0606 - acc: 0.5640
 864/9062 [=>............................] - ETA: 23s - loss: 0.9845 - acc: 0.5486
1056/9062 [==>...........................] - ETA: 19s - loss: 0.9621 - acc: 0.5246
1248/9062 [===>..........................] - ETA: 16s - loss: 0.9233 - acc: 0.5224
1440/9062 [===>..........................] - ETA: 13s - loss: 0.8928 - acc: 0.5264
1632/9062 [====>.........................] - ETA: 12s - loss: 0.8709 - acc: 0.5355
1824/9062 [=====>........................] - ETA: 10s - loss: 0.8553 - acc: 0.5406
2016/9062 [=====>........................] - ETA: 9s - loss: 0.8390 - acc: 0.5481 
2208/9062 [======>.......................] - ETA: 8s - loss: 0.8252 - acc: 0.5507
2400/9062 [======>.......................] - ETA: 8s - loss: 0.8143 - acc: 0.5492
2592/9062 [=======>......................] - ETA: 7s - loss: 0.8041 - acc: 0.5517
2784/9062 [========>.....................] - ETA: 6s - loss: 0.7946 - acc: 0.5546
2976/9062 [========>.....................] - ETA: 6s - loss: 0.7883 - acc: 0.5551
3168/9062 [=========>....................] - ETA: 5s - loss: 0.7844 - acc: 0.5521
3360/9062 [==========>...................] - ETA: 5s - loss: 0.7785 - acc: 0.5527
3552/9062 [==========>...................] - ETA: 5s - loss: 0.7737 - acc: 0.5510
3744/9062 [===========>..................] - ETA: 4s - loss: 0.7691 - acc: 0.5502
3936/9062 [============>.................] - ETA: 4s - loss: 0.7638 - acc: 0.5526
4128/9062 [============>.................] - ETA: 4s - loss: 0.7609 - acc: 0.5526
4320/9062 [=============>................] - ETA: 3s - loss: 0.7561 - acc: 0.5560
4512/9062 [=============>................] - ETA: 3s - loss: 0.7546 - acc: 0.5530
4704/9062 [==============>...............] - ETA: 3s - loss: 0.7512 - acc: 0.5548
4896/9062 [===============>..............] - ETA: 3s - loss: 0.7486 - acc: 0.5556
5088/9062 [===============>..............] - ETA: 2s - loss: 0.7460 - acc: 0.5562
5280/9062 [================>.............] - ETA: 2s - loss: 0.7427 - acc: 0.5595
5472/9062 [=================>............] - ETA: 2s - loss: 0.7405 - acc: 0.5607
5664/9062 [=================>............] - ETA: 2s - loss: 0.7392 - acc: 0.5614
5856/9062 [==================>...........] - ETA: 2s - loss: 0.7369 - acc: 0.5628
6048/9062 [===================>..........] - ETA: 1s - loss: 0.7349 - acc: 0.5635
6240/9062 [===================>..........] - ETA: 1s - loss: 0.7333 - acc: 0.5638
6432/9062 [====================>.........] - ETA: 1s - loss: 0.7309 - acc: 0.5664
6624/9062 [====================>.........] - ETA: 1s - loss: 0.7286 - acc: 0.5675
6816/9062 [=====================>........] - ETA: 1s - loss: 0.7269 - acc: 0.5687
7008/9062 [======================>.......] - ETA: 1s - loss: 0.7252 - acc: 0.5696
7200/9062 [======================>.......] - ETA: 1s - loss: 0.7232 - acc: 0.5711
7392/9062 [=======================>......] - ETA: 0s - loss: 0.7210 - acc: 0.5743
7584/9062 [========================>.....] - ETA: 0s - loss: 0.7191 - acc: 0.5756
7776/9062 [========================>.....] - ETA: 0s - loss: 0.7177 - acc: 0.5759
7968/9062 [=========================>....] - ETA: 0s - loss: 0.7163 - acc: 0.5767
8160/9062 [==========================>...] - ETA: 0s - loss: 0.7145 - acc: 0.5792
8352/9062 [==========================>...] - ETA: 0s - loss: 0.7130 - acc: 0.5817
8544/9062 [===========================>..] - ETA: 0s - loss: 0.7119 - acc: 0.5818
8736/9062 [===========================>..] - ETA: 0s - loss: 0.7098 - acc: 0.5836
8928/9062 [============================>.] - ETA: 0s - loss: 0.7091 - acc: 0.5831
9062/9062 [==============================] - 6s 637us/step - loss: 0.7083 - acc: 0.5843 - val_loss: 0.4336 - val_acc: 0.9131
Epoch 2/30

  96/9062 [..............................] - ETA: 2s - loss: 0.6626 - acc: 0.5312
 192/9062 [..............................] - ETA: 6s - loss: 0.6894 - acc: 0.5052
 384/9062 [>.............................] - ETA: 4s - loss: 0.6724 - acc: 0.5625
 576/9062 [>.............................] - ETA: 3s - loss: 0.6733 - acc: 0.5781
 768/9062 [=>............................] - ETA: 3s - loss: 0.6506 - acc: 0.6146
 960/9062 [==>...........................] - ETA: 3s - loss: 0.6368 - acc: 0.6385
1152/9062 [==>...........................] - ETA: 2s - loss: 0.6262 - acc: 0.6476
1344/9062 [===>..........................] - ETA: 2s - loss: 0.6225 - acc: 0.6525
1536/9062 [====>.........................] - ETA: 2s - loss: 0.6160 - acc: 0.6589
1728/9062 [====>.........................] - ETA: 2s - loss: 0.6166 - acc: 0.6626
1920/9062 [=====>........................] - ETA: 2s - loss: 0.6128 - acc: 0.6667
2112/9062 [=====>........................] - ETA: 2s - loss: 0.6135 - acc: 0.6652
2304/9062 [======>.......................] - ETA: 2s - loss: 0.6139 - acc: 0.6667
2496/9062 [=======>......................] - ETA: 2s - loss: 0.6104 - acc: 0.6683
2688/9062 [=======>......................] - ETA: 2s - loss: 0.6098 - acc: 0.6667
2880/9062 [========>.....................] - ETA: 1s - loss: 0.6105 - acc: 0.6642
3072/9062 [=========>....................] - ETA: 1s - loss: 0.6104 - acc: 0.6650
3264/9062 [=========>....................] - ETA: 1s - loss: 0.6071 - acc: 0.6691
3456/9062 [==========>...................] - ETA: 1s - loss: 0.6037 - acc: 0.6722
3648/9062 [===========>..................] - ETA: 1s - loss: 0.6046 - acc: 0.6708
3840/9062 [===========>..................] - ETA: 1s - loss: 0.6019 - acc: 0.6755
4032/9062 [============>.................] - ETA: 1s - loss: 0.6021 - acc: 0.6734
4224/9062 [============>.................] - ETA: 1s - loss: 0.6025 - acc: 0.6714
4416/9062 [=============>................] - ETA: 1s - loss: 0.6011 - acc: 0.6735
4608/9062 [==============>...............] - ETA: 1s - loss: 0.5989 - acc: 0.6749
4800/9062 [==============>...............] - ETA: 1s - loss: 0.5968 - acc: 0.6775
4992/9062 [===============>..............] - ETA: 1s - loss: 0.5956 - acc: 0.6795
5184/9062 [================>.............] - ETA: 1s - loss: 0.5945 - acc: 0.6796
5376/9062 [================>.............] - ETA: 1s - loss: 0.5934 - acc: 0.6806
5568/9062 [=================>............] - ETA: 1s - loss: 0.5938 - acc: 0.6810
5760/9062 [==================>...........] - ETA: 1s - loss: 0.5926 - acc: 0.6818
5952/9062 [==================>...........] - ETA: 0s - loss: 0.5946 - acc: 0.6808
6144/9062 [===================>..........] - ETA: 0s - loss: 0.5949 - acc: 0.6800
6336/9062 [===================>..........] - ETA: 0s - loss: 0.5915 - acc: 0.6832
6528/9062 [====================>.........] - ETA: 0s - loss: 0.5894 - acc: 0.6850
6720/9062 [=====================>........] - ETA: 0s - loss: 0.5896 - acc: 0.6847
6912/9062 [=====================>........] - ETA: 0s - loss: 0.5880 - acc: 0.6862
7104/9062 [======================>.......] - ETA: 0s - loss: 0.5873 - acc: 0.6868
7296/9062 [=======================>......] - ETA: 0s - loss: 0.5881 - acc: 0.6865
7488/9062 [=======================>......] - ETA: 0s - loss: 0.5868 - acc: 0.6880
7680/9062 [========================>.....] - ETA: 0s - loss: 0.5862 - acc: 0.6888
7872/9062 [=========================>....] - ETA: 0s - loss: 0.5856 - acc: 0.6894
8064/9062 [=========================>....] - ETA: 0s - loss: 0.5853 - acc: 0.6902
8256/9062 [==========================>...] - ETA: 0s - loss: 0.5840 - acc: 0.6913
8448/9062 [==========================>...] - ETA: 0s - loss: 0.5834 - acc: 0.6919
8640/9062 [===========================>..] - ETA: 0s - loss: 0.5829 - acc: 0.6926
8832/9062 [============================>.] - ETA: 0s - loss: 0.5826 - acc: 0.6932
9024/9062 [============================>.] - ETA: 0s - loss: 0.5820 - acc: 0.6936
9062/9062 [==============================] - 3s 312us/step - loss: 0.5819 - acc: 0.6938 - val_loss: 0.6274 - val_acc: 0.6338
Epoch 3/30

  96/9062 [..............................] - ETA: 2s - loss: 0.4807 - acc: 0.7812
 288/9062 [..............................] - ETA: 2s - loss: 0.5680 - acc: 0.7326
 480/9062 [>.............................] - ETA: 2s - loss: 0.5566 - acc: 0.7292
 672/9062 [=>............................] - ETA: 2s - loss: 0.5345 - acc: 0.7560
 864/9062 [=>............................] - ETA: 2s - loss: 0.5420 - acc: 0.7454
1056/9062 [==>...........................] - ETA: 2s - loss: 0.5386 - acc: 0.7386
1248/9062 [===>..........................] - ETA: 2s - loss: 0.5427 - acc: 0.7332
1440/9062 [===>..........................] - ETA: 2s - loss: 0.5322 - acc: 0.7410
1632/9062 [====>.........................] - ETA: 2s - loss: 0.5287 - acc: 0.7439
1824/9062 [=====>........................] - ETA: 2s - loss: 0.5272 - acc: 0.7473
2016/9062 [=====>........................] - ETA: 2s - loss: 0.5261 - acc: 0.7436
2208/9062 [======>.......................] - ETA: 1s - loss: 0.5230 - acc: 0.7450
2400/9062 [======>.......................] - ETA: 1s - loss: 0.5236 - acc: 0.7437
2592/9062 [=======>......................] - ETA: 1s - loss: 0.5214 - acc: 0.7438
2784/9062 [========>.....................] - ETA: 1s - loss: 0.5179 - acc: 0.7453
2976/9062 [========>.....................] - ETA: 1s - loss: 0.5198 - acc: 0.7446
3168/9062 [=========>....................] - ETA: 1s - loss: 0.5223 - acc: 0.7412
3360/9062 [==========>...................] - ETA: 1s - loss: 0.5225 - acc: 0.7405
3552/9062 [==========>...................] - ETA: 1s - loss: 0.5236 - acc: 0.7401
3744/9062 [===========>..................] - ETA: 1s - loss: 0.5219 - acc: 0.7399
3936/9062 [============>.................] - ETA: 1s - loss: 0.5204 - acc: 0.7419
4128/9062 [============>.................] - ETA: 1s - loss: 0.5185 - acc: 0.7437
4320/9062 [=============>................] - ETA: 1s - loss: 0.5168 - acc: 0.7449
4512/9062 [=============>................] - ETA: 1s - loss: 0.5179 - acc: 0.7440
4704/9062 [==============>...............] - ETA: 1s - loss: 0.5160 - acc: 0.7451
4896/9062 [===============>..............] - ETA: 1s - loss: 0.5148 - acc: 0.7449
5088/9062 [===============>..............] - ETA: 1s - loss: 0.5143 - acc: 0.7443
5280/9062 [================>.............] - ETA: 1s - loss: 0.5107 - acc: 0.7473
5472/9062 [=================>............] - ETA: 1s - loss: 0.5112 - acc: 0.7474
5664/9062 [=================>............] - ETA: 0s - loss: 0.5120 - acc: 0.7474
5856/9062 [==================>...........] - ETA: 0s - loss: 0.5101 - acc: 0.7488
6048/9062 [===================>..........] - ETA: 0s - loss: 0.5115 - acc: 0.7475
6240/9062 [===================>..........] - ETA: 0s - loss: 0.5140 - acc: 0.7462
6432/9062 [====================>.........] - ETA: 0s - loss: 0.5144 - acc: 0.7456
6624/9062 [====================>.........] - ETA: 0s - loss: 0.5132 - acc: 0.7464
6816/9062 [=====================>........] - ETA: 0s - loss: 0.5138 - acc: 0.7460
7008/9062 [======================>.......] - ETA: 0s - loss: 0.5139 - acc: 0.7457
7200/9062 [======================>.......] - ETA: 0s - loss: 0.5138 - acc: 0.7460
7392/9062 [=======================>......] - ETA: 0s - loss: 0.5131 - acc: 0.7469
7584/9062 [========================>.....] - ETA: 0s - loss: 0.5118 - acc: 0.7478
7776/9062 [========================>.....] - ETA: 0s - loss: 0.5097 - acc: 0.7494
7968/9062 [=========================>....] - ETA: 0s - loss: 0.5088 - acc: 0.7506
8160/9062 [==========================>...] - ETA: 0s - loss: 0.5094 - acc: 0.7506
8352/9062 [==========================>...] - ETA: 0s - loss: 0.5095 - acc: 0.7498
8544/9062 [===========================>..] - ETA: 0s - loss: 0.5085 - acc: 0.7509
8736/9062 [===========================>..] - ETA: 0s - loss: 0.5075 - acc: 0.7518
8928/9062 [============================>.] - ETA: 0s - loss: 0.5070 - acc: 0.7518
9062/9062 [==============================] - 3s 303us/step - loss: 0.5065 - acc: 0.7520 - val_loss: 0.9306 - val_acc: 0.4787
Epoch 4/30

  96/9062 [..............................] - ETA: 2s - loss: 0.4610 - acc: 0.7708
 288/9062 [..............................] - ETA: 2s - loss: 0.5070 - acc: 0.7604
 480/9062 [>.............................] - ETA: 2s - loss: 0.4818 - acc: 0.7771
 672/9062 [=>............................] - ETA: 2s - loss: 0.4667 - acc: 0.7872
 864/9062 [=>............................] - ETA: 2s - loss: 0.4625 - acc: 0.7870
1056/9062 [==>...........................] - ETA: 2s - loss: 0.4648 - acc: 0.7831
1248/9062 [===>..........................] - ETA: 2s - loss: 0.4718 - acc: 0.7812
1440/9062 [===>..........................] - ETA: 2s - loss: 0.4725 - acc: 0.7806
1632/9062 [====>.........................] - ETA: 2s - loss: 0.4736 - acc: 0.7806
1824/9062 [=====>........................] - ETA: 2s - loss: 0.4733 - acc: 0.7769
2016/9062 [=====>........................] - ETA: 2s - loss: 0.4701 - acc: 0.7768
2208/9062 [======>.......................] - ETA: 1s - loss: 0.4678 - acc: 0.7799
2400/9062 [======>.......................] - ETA: 1s - loss: 0.4680 - acc: 0.7779
2592/9062 [=======>......................] - ETA: 1s - loss: 0.4624 - acc: 0.7828
2784/9062 [========>.....................] - ETA: 1s - loss: 0.4576 - acc: 0.7848
2976/9062 [========>.....................] - ETA: 1s - loss: 0.4554 - acc: 0.7870
3168/9062 [=========>....................] - ETA: 1s - loss: 0.4559 - acc: 0.7863
3360/9062 [==========>...................] - ETA: 1s - loss: 0.4507 - acc: 0.7881
3552/9062 [==========>...................] - ETA: 1s - loss: 0.4457 - acc: 0.7905
3744/9062 [===========>..................] - ETA: 1s - loss: 0.4481 - acc: 0.7887
3936/9062 [============>.................] - ETA: 1s - loss: 0.4484 - acc: 0.7881
4128/9062 [============>.................] - ETA: 1s - loss: 0.4501 - acc: 0.7859
4320/9062 [=============>................] - ETA: 1s - loss: 0.4498 - acc: 0.7873
4512/9062 [=============>................] - ETA: 1s - loss: 0.4512 - acc: 0.7863
4704/9062 [==============>...............] - ETA: 1s - loss: 0.4547 - acc: 0.7849
4896/9062 [===============>..............] - ETA: 1s - loss: 0.4533 - acc: 0.7870
5088/9062 [===============>..............] - ETA: 1s - loss: 0.4548 - acc: 0.7856
5280/9062 [================>.............] - ETA: 1s - loss: 0.4540 - acc: 0.7858
5472/9062 [=================>............] - ETA: 1s - loss: 0.4499 - acc: 0.7889
5664/9062 [=================>............] - ETA: 0s - loss: 0.4493 - acc: 0.7888
5856/9062 [==================>...........] - ETA: 0s - loss: 0.4505 - acc: 0.7877
6048/9062 [===================>..........] - ETA: 0s - loss: 0.4510 - acc: 0.7867
6240/9062 [===================>..........] - ETA: 0s - loss: 0.4510 - acc: 0.7861
6432/9062 [====================>.........] - ETA: 0s - loss: 0.4501 - acc: 0.7861
6624/9062 [====================>.........] - ETA: 0s - loss: 0.4506 - acc: 0.7856
6816/9062 [=====================>........] - ETA: 0s - loss: 0.4497 - acc: 0.7870
7008/9062 [======================>.......] - ETA: 0s - loss: 0.4500 - acc: 0.7872
7200/9062 [======================>.......] - ETA: 0s - loss: 0.4481 - acc: 0.7887
7392/9062 [=======================>......] - ETA: 0s - loss: 0.4472 - acc: 0.7896
7584/9062 [========================>.....] - ETA: 0s - loss: 0.4465 - acc: 0.7896
7776/9062 [========================>.....] - ETA: 0s - loss: 0.4464 - acc: 0.7891
7968/9062 [=========================>....] - ETA: 0s - loss: 0.4459 - acc: 0.7890
8160/9062 [==========================>...] - ETA: 0s - loss: 0.4451 - acc: 0.7896
8352/9062 [==========================>...] - ETA: 0s - loss: 0.4447 - acc: 0.7906
8544/9062 [===========================>..] - ETA: 0s - loss: 0.4458 - acc: 0.7906
8736/9062 [===========================>..] - ETA: 0s - loss: 0.4447 - acc: 0.7918
8928/9062 [============================>.] - ETA: 0s - loss: 0.4459 - acc: 0.7913
9062/9062 [==============================] - 3s 302us/step - loss: 0.4455 - acc: 0.7913 - val_loss: 0.6630 - val_acc: 0.6388
Epoch 5/30

  96/9062 [..............................] - ETA: 2s - loss: 0.3789 - acc: 0.8438
 288/9062 [..............................] - ETA: 2s - loss: 0.3407 - acc: 0.8576
 384/9062 [>.............................] - ETA: 3s - loss: 0.3620 - acc: 0.8385
 576/9062 [>.............................] - ETA: 3s - loss: 0.3649 - acc: 0.8351
 768/9062 [=>............................] - ETA: 3s - loss: 0.3931 - acc: 0.8177
 960/9062 [==>...........................] - ETA: 2s - loss: 0.3901 - acc: 0.8208
1152/9062 [==>...........................] - ETA: 2s - loss: 0.4036 - acc: 0.8134
1344/9062 [===>..........................] - ETA: 2s - loss: 0.3974 - acc: 0.8199
1536/9062 [====>.........................] - ETA: 2s - loss: 0.4153 - acc: 0.8099
1728/9062 [====>.........................] - ETA: 2s - loss: 0.4164 - acc: 0.8056
1920/9062 [=====>........................] - ETA: 2s - loss: 0.4141 - acc: 0.8099
2112/9062 [=====>........................] - ETA: 2s - loss: 0.4093 - acc: 0.8125
2304/9062 [======>.......................] - ETA: 2s - loss: 0.4116 - acc: 0.8108
2496/9062 [=======>......................] - ETA: 2s - loss: 0.4057 - acc: 0.8169
2688/9062 [=======>......................] - ETA: 1s - loss: 0.4020 - acc: 0.8192
2880/9062 [========>.....................] - ETA: 1s - loss: 0.4000 - acc: 0.8201
3072/9062 [=========>....................] - ETA: 1s - loss: 0.4000 - acc: 0.8206
3264/9062 [=========>....................] - ETA: 1s - loss: 0.3976 - acc: 0.8229
3456/9062 [==========>...................] - ETA: 1s - loss: 0.3941 - acc: 0.8232
3648/9062 [===========>..................] - ETA: 1s - loss: 0.3958 - acc: 0.8215
3840/9062 [===========>..................] - ETA: 1s - loss: 0.3978 - acc: 0.8203
4032/9062 [============>.................] - ETA: 1s - loss: 0.3983 - acc: 0.8187
4224/9062 [============>.................] - ETA: 1s - loss: 0.3979 - acc: 0.8182
4416/9062 [=============>................] - ETA: 1s - loss: 0.3988 - acc: 0.8177
4608/9062 [==============>...............] - ETA: 1s - loss: 0.3972 - acc: 0.8186
4800/9062 [==============>...............] - ETA: 1s - loss: 0.3944 - acc: 0.8204
4992/9062 [===============>..............] - ETA: 1s - loss: 0.3933 - acc: 0.8209
5184/9062 [================>.............] - ETA: 1s - loss: 0.3918 - acc: 0.8208
5376/9062 [================>.............] - ETA: 1s - loss: 0.3909 - acc: 0.8207
5568/9062 [=================>............] - ETA: 1s - loss: 0.3913 - acc: 0.8199
5760/9062 [==================>...........] - ETA: 0s - loss: 0.3901 - acc: 0.8207
5952/9062 [==================>...........] - ETA: 0s - loss: 0.3924 - acc: 0.8204
6144/9062 [===================>..........] - ETA: 0s - loss: 0.3920 - acc: 0.8201
6336/9062 [===================>..........] - ETA: 0s - loss: 0.3920 - acc: 0.8201
6528/9062 [====================>.........] - ETA: 0s - loss: 0.3935 - acc: 0.8197
6720/9062 [=====================>........] - ETA: 0s - loss: 0.3925 - acc: 0.8202
6912/9062 [=====================>........] - ETA: 0s - loss: 0.3927 - acc: 0.8203
7104/9062 [======================>.......] - ETA: 0s - loss: 0.3930 - acc: 0.8204
7296/9062 [=======================>......] - ETA: 0s - loss: 0.3933 - acc: 0.8204
7488/9062 [=======================>......] - ETA: 0s - loss: 0.3972 - acc: 0.8188
7680/9062 [========================>.....] - ETA: 0s - loss: 0.3975 - acc: 0.8182
7872/9062 [=========================>....] - ETA: 0s - loss: 0.3992 - acc: 0.8173
8064/9062 [=========================>....] - ETA: 0s - loss: 0.3996 - acc: 0.8168
8256/9062 [==========================>...] - ETA: 0s - loss: 0.4008 - acc: 0.8158
8448/9062 [==========================>...] - ETA: 0s - loss: 0.4007 - acc: 0.8156
8640/9062 [===========================>..] - ETA: 0s - loss: 0.4005 - acc: 0.8159
8832/9062 [============================>.] - ETA: 0s - loss: 0.3987 - acc: 0.8167
9024/9062 [============================>.] - ETA: 0s - loss: 0.3987 - acc: 0.8168
9062/9062 [==============================] - 3s 310us/step - loss: 0.3988 - acc: 0.8167 - val_loss: 0.8166 - val_acc: 0.6187
Epoch 6/30

  96/9062 [..............................] - ETA: 2s - loss: 0.2711 - acc: 0.8750
 288/9062 [..............................] - ETA: 2s - loss: 0.3051 - acc: 0.8507
 480/9062 [>.............................] - ETA: 2s - loss: 0.3246 - acc: 0.8458
 672/9062 [=>............................] - ETA: 2s - loss: 0.3229 - acc: 0.8467
 864/9062 [=>............................] - ETA: 2s - loss: 0.3324 - acc: 0.8461
1056/9062 [==>...........................] - ETA: 2s - loss: 0.3384 - acc: 0.8447
1248/9062 [===>..........................] - ETA: 2s - loss: 0.3206 - acc: 0.8526
1440/9062 [===>..........................] - ETA: 2s - loss: 0.3327 - acc: 0.8479
1632/9062 [====>.........................] - ETA: 2s - loss: 0.3308 - acc: 0.8480
1824/9062 [=====>........................] - ETA: 2s - loss: 0.3252 - acc: 0.8509
2016/9062 [=====>........................] - ETA: 2s - loss: 0.3269 - acc: 0.8497
2208/9062 [======>.......................] - ETA: 1s - loss: 0.3231 - acc: 0.8505
2400/9062 [======>.......................] - ETA: 1s - loss: 0.3206 - acc: 0.8525
2592/9062 [=======>......................] - ETA: 1s - loss: 0.3227 - acc: 0.8515
2784/9062 [========>.....................] - ETA: 1s - loss: 0.3240 - acc: 0.8499
2976/9062 [========>.....................] - ETA: 1s - loss: 0.3241 - acc: 0.8501
3168/9062 [=========>....................] - ETA: 1s - loss: 0.3278 - acc: 0.8494
3360/9062 [==========>...................] - ETA: 1s - loss: 0.3304 - acc: 0.8479
3552/9062 [==========>...................] - ETA: 1s - loss: 0.3347 - acc: 0.8460
3744/9062 [===========>..................] - ETA: 1s - loss: 0.3338 - acc: 0.8470
3936/9062 [============>.................] - ETA: 1s - loss: 0.3343 - acc: 0.8465
4128/9062 [============>.................] - ETA: 1s - loss: 0.3358 - acc: 0.8464
4320/9062 [=============>................] - ETA: 1s - loss: 0.3356 - acc: 0.8465
4512/9062 [=============>................] - ETA: 1s - loss: 0.3372 - acc: 0.8457
4704/9062 [==============>...............] - ETA: 1s - loss: 0.3385 - acc: 0.8442
4896/9062 [===============>..............] - ETA: 1s - loss: 0.3413 - acc: 0.8423
5088/9062 [===============>..............] - ETA: 1s - loss: 0.3447 - acc: 0.8400
5280/9062 [================>.............] - ETA: 1s - loss: 0.3443 - acc: 0.8405
5472/9062 [=================>............] - ETA: 1s - loss: 0.3429 - acc: 0.8410
5664/9062 [=================>............] - ETA: 0s - loss: 0.3454 - acc: 0.8395
5856/9062 [==================>...........] - ETA: 0s - loss: 0.3456 - acc: 0.8403
6048/9062 [===================>..........] - ETA: 0s - loss: 0.3453 - acc: 0.8406
6240/9062 [===================>..........] - ETA: 0s - loss: 0.3468 - acc: 0.8407
6432/9062 [====================>.........] - ETA: 0s - loss: 0.3474 - acc: 0.8411
6624/9062 [====================>.........] - ETA: 0s - loss: 0.3475 - acc: 0.8407
6816/9062 [=====================>........] - ETA: 0s - loss: 0.3490 - acc: 0.8391
7008/9062 [======================>.......] - ETA: 0s - loss: 0.3480 - acc: 0.8400
7200/9062 [======================>.......] - ETA: 0s - loss: 0.3487 - acc: 0.8401
7392/9062 [=======================>......] - ETA: 0s - loss: 0.3490 - acc: 0.8404
7584/9062 [========================>.....] - ETA: 0s - loss: 0.3483 - acc: 0.8410
7776/9062 [========================>.....] - ETA: 0s - loss: 0.3478 - acc: 0.8413
7968/9062 [=========================>....] - ETA: 0s - loss: 0.3492 - acc: 0.8397
8160/9062 [==========================>...] - ETA: 0s - loss: 0.3471 - acc: 0.8411
8352/9062 [==========================>...] - ETA: 0s - loss: 0.3502 - acc: 0.8403
8544/9062 [===========================>..] - ETA: 0s - loss: 0.3514 - acc: 0.8397
8736/9062 [===========================>..] - ETA: 0s - loss: 0.3514 - acc: 0.8395
8928/9062 [============================>.] - ETA: 0s - loss: 0.3495 - acc: 0.8404
9062/9062 [==============================] - 3s 303us/step - loss: 0.3496 - acc: 0.8411 - val_loss: 1.0003 - val_acc: 0.5494
Epoch 7/30

  96/9062 [..............................] - ETA: 2s - loss: 0.4063 - acc: 0.8333
 288/9062 [..............................] - ETA: 2s - loss: 0.3462 - acc: 0.8576
 480/9062 [>.............................] - ETA: 2s - loss: 0.3110 - acc: 0.8771
 672/9062 [=>............................] - ETA: 2s - loss: 0.3063 - acc: 0.8780
 864/9062 [=>............................] - ETA: 2s - loss: 0.2988 - acc: 0.8831
1056/9062 [==>...........................] - ETA: 2s - loss: 0.2991 - acc: 0.8826
1248/9062 [===>..........................] - ETA: 2s - loss: 0.2964 - acc: 0.8806
1440/9062 [===>..........................] - ETA: 2s - loss: 0.3046 - acc: 0.8785
1632/9062 [====>.........................] - ETA: 2s - loss: 0.3074 - acc: 0.8725
1824/9062 [=====>........................] - ETA: 2s - loss: 0.3093 - acc: 0.8717
2016/9062 [=====>........................] - ETA: 2s - loss: 0.3083 - acc: 0.8710
2208/9062 [======>.......................] - ETA: 1s - loss: 0.3063 - acc: 0.8723
2400/9062 [======>.......................] - ETA: 1s - loss: 0.3109 - acc: 0.8675
2592/9062 [=======>......................] - ETA: 1s - loss: 0.3115 - acc: 0.8654
2784/9062 [========>.....................] - ETA: 1s - loss: 0.3077 - acc: 0.8667
2976/9062 [========>.....................] - ETA: 1s - loss: 0.3053 - acc: 0.8686
3168/9062 [=========>....................] - ETA: 1s - loss: 0.3033 - acc: 0.8690
3360/9062 [==========>...................] - ETA: 1s - loss: 0.3049 - acc: 0.8685
3552/9062 [==========>...................] - ETA: 1s - loss: 0.3047 - acc: 0.8688
3744/9062 [===========>..................] - ETA: 1s - loss: 0.3064 - acc: 0.8686
3936/9062 [============>.................] - ETA: 1s - loss: 0.3046 - acc: 0.8694
4128/9062 [============>.................] - ETA: 1s - loss: 0.3045 - acc: 0.8692
4320/9062 [=============>................] - ETA: 1s - loss: 0.3046 - acc: 0.8692
4512/9062 [=============>................] - ETA: 1s - loss: 0.3102 - acc: 0.8659
4704/9062 [==============>...............] - ETA: 1s - loss: 0.3075 - acc: 0.8682
4896/9062 [===============>..............] - ETA: 1s - loss: 0.3086 - acc: 0.8668
5088/9062 [===============>..............] - ETA: 1s - loss: 0.3085 - acc: 0.8665
5280/9062 [================>.............] - ETA: 1s - loss: 0.3071 - acc: 0.8676
5472/9062 [=================>............] - ETA: 1s - loss: 0.3047 - acc: 0.8693
5664/9062 [=================>............] - ETA: 0s - loss: 0.3053 - acc: 0.8694
5856/9062 [==================>...........] - ETA: 0s - loss: 0.3041 - acc: 0.8697
6048/9062 [===================>..........] - ETA: 0s - loss: 0.3024 - acc: 0.8705
6240/9062 [===================>..........] - ETA: 0s - loss: 0.3016 - acc: 0.8708
6432/9062 [====================>.........] - ETA: 0s - loss: 0.3007 - acc: 0.8711
6624/9062 [====================>.........] - ETA: 0s - loss: 0.3003 - acc: 0.8720
6816/9062 [=====================>........] - ETA: 0s - loss: 0.3010 - acc: 0.8710
7008/9062 [======================>.......] - ETA: 0s - loss: 0.2998 - acc: 0.8716
7200/9062 [======================>.......] - ETA: 0s - loss: 0.2997 - acc: 0.8712
7392/9062 [=======================>......] - ETA: 0s - loss: 0.3004 - acc: 0.8703
7584/9062 [========================>.....] - ETA: 0s - loss: 0.3010 - acc: 0.8704
7776/9062 [========================>.....] - ETA: 0s - loss: 0.3025 - acc: 0.8701
7968/9062 [=========================>....] - ETA: 0s - loss: 0.3014 - acc: 0.8711
8160/9062 [==========================>...] - ETA: 0s - loss: 0.3011 - acc: 0.8712
8352/9062 [==========================>...] - ETA: 0s - loss: 0.3025 - acc: 0.8705
8544/9062 [===========================>..] - ETA: 0s - loss: 0.3028 - acc: 0.8707
8736/9062 [===========================>..] - ETA: 0s - loss: 0.3028 - acc: 0.8709
8928/9062 [============================>.] - ETA: 0s - loss: 0.3033 - acc: 0.8703
9062/9062 [==============================] - 3s 304us/step - loss: 0.3046 - acc: 0.8697 - val_loss: 0.8503 - val_acc: 0.6419
Epoch 8/30

  96/9062 [..............................] - ETA: 2s - loss: 0.3123 - acc: 0.8750
 288/9062 [..............................] - ETA: 2s - loss: 0.3065 - acc: 0.8611
 480/9062 [>.............................] - ETA: 2s - loss: 0.2968 - acc: 0.8687
 672/9062 [=>............................] - ETA: 2s - loss: 0.3039 - acc: 0.8720
 864/9062 [=>............................] - ETA: 2s - loss: 0.3071 - acc: 0.8681
1056/9062 [==>...........................] - ETA: 2s - loss: 0.3103 - acc: 0.8674
1248/9062 [===>..........................] - ETA: 2s - loss: 0.2975 - acc: 0.8758
1440/9062 [===>..........................] - ETA: 2s - loss: 0.2910 - acc: 0.8785
1632/9062 [====>.........................] - ETA: 2s - loss: 0.2817 - acc: 0.8824
1824/9062 [=====>........................] - ETA: 2s - loss: 0.2774 - acc: 0.8849
2016/9062 [=====>........................] - ETA: 2s - loss: 0.2694 - acc: 0.8884
2208/9062 [======>.......................] - ETA: 1s - loss: 0.2696 - acc: 0.8904
2400/9062 [======>.......................] - ETA: 1s - loss: 0.2706 - acc: 0.8892
2592/9062 [=======>......................] - ETA: 1s - loss: 0.2746 - acc: 0.8889
2784/9062 [========>.....................] - ETA: 1s - loss: 0.2759 - acc: 0.8886
2976/9062 [========>.....................] - ETA: 1s - loss: 0.2718 - acc: 0.8908
3168/9062 [=========>....................] - ETA: 1s - loss: 0.2684 - acc: 0.8930
3360/9062 [==========>...................] - ETA: 1s - loss: 0.2690 - acc: 0.8926
3552/9062 [==========>...................] - ETA: 1s - loss: 0.2704 - acc: 0.8910
3744/9062 [===========>..................] - ETA: 1s - loss: 0.2672 - acc: 0.8926
3840/9062 [===========>..................] - ETA: 1s - loss: 0.2655 - acc: 0.8938
4032/9062 [============>.................] - ETA: 1s - loss: 0.2645 - acc: 0.8941
4224/9062 [============>.................] - ETA: 1s - loss: 0.2636 - acc: 0.8944
4416/9062 [=============>................] - ETA: 1s - loss: 0.2622 - acc: 0.8942
4608/9062 [==============>...............] - ETA: 1s - loss: 0.2657 - acc: 0.8930
4800/9062 [==============>...............] - ETA: 1s - loss: 0.2676 - acc: 0.8927
4992/9062 [===============>..............] - ETA: 1s - loss: 0.2692 - acc: 0.8918
5184/9062 [================>.............] - ETA: 1s - loss: 0.2687 - acc: 0.8920
5376/9062 [================>.............] - ETA: 1s - loss: 0.2672 - acc: 0.8927
5568/9062 [=================>............] - ETA: 1s - loss: 0.2671 - acc: 0.8926
5760/9062 [==================>...........] - ETA: 1s - loss: 0.2700 - acc: 0.8911
5952/9062 [==================>...........] - ETA: 0s - loss: 0.2707 - acc: 0.8910
6144/9062 [===================>..........] - ETA: 0s - loss: 0.2709 - acc: 0.8905
6336/9062 [===================>..........] - ETA: 0s - loss: 0.2706 - acc: 0.8897
6528/9062 [====================>.........] - ETA: 0s - loss: 0.2695 - acc: 0.8892
6720/9062 [=====================>........] - ETA: 0s - loss: 0.2686 - acc: 0.8894
6912/9062 [=====================>........] - ETA: 0s - loss: 0.2680 - acc: 0.8900
7104/9062 [======================>.......] - ETA: 0s - loss: 0.2700 - acc: 0.8888
7296/9062 [=======================>......] - ETA: 0s - loss: 0.2696 - acc: 0.8891
7488/9062 [=======================>......] - ETA: 0s - loss: 0.2708 - acc: 0.8885
7680/9062 [========================>.....] - ETA: 0s - loss: 0.2693 - acc: 0.8895
7872/9062 [=========================>....] - ETA: 0s - loss: 0.2680 - acc: 0.8906
8064/9062 [=========================>....] - ETA: 0s - loss: 0.2682 - acc: 0.8903
8256/9062 [==========================>...] - ETA: 0s - loss: 0.2667 - acc: 0.8911
8448/9062 [==========================>...] - ETA: 0s - loss: 0.2659 - acc: 0.8915
8640/9062 [===========================>..] - ETA: 0s - loss: 0.2656 - acc: 0.8917
8832/9062 [============================>.] - ETA: 0s - loss: 0.2656 - acc: 0.8915
9024/9062 [============================>.] - ETA: 0s - loss: 0.2666 - acc: 0.8907
9062/9062 [==============================] - 3s 315us/step - loss: 0.2666 - acc: 0.8908 - val_loss: 0.9150 - val_acc: 0.6756
Using TensorFlow backend.
/home/vbd667/anaconda3/envs/python36/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
/home/vbd667/code/GAHs/models/GAHs.py:215: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor("de...)`
  return Model(input = input_list, output= preds)
Current Model: Transformer
[search time]: 3 / 30
[paras]: modelgahs_hidden_unit_num200_dropout_rate0.2_lr0.001_batch_size96_val_split0.15_layers2_n_head4_d_inner_hid256_roles['positional', 'both_direct', 'stop_word', 'POS']_
Traceback (most recent call last):
  File "train.py", line 116, in <module>
    train_grid(args)
  File "train.py", line 93, in train_grid
    model = models.setup(opt)
  File "/home/vbd667/code/GAHs/models/__init__.py", line 21, in setup
    model = GAHs(opt)
  File "/home/vbd667/code/GAHs/models/BasicModel.py", line 28, in __init__
    self.model = self.get_model(opt)
  File "/home/vbd667/code/GAHs/models/GAHs.py", line 215, in get_model
    return Model(input = input_list, output= preds)
  File "/home/vbd667/anaconda3/envs/python36/lib/python3.6/site-packages/keras/legacy/interfaces.py", line 91, in wrapper
    return func(*args, **kwargs)
  File "/home/vbd667/anaconda3/envs/python36/lib/python3.6/site-packages/keras/engine/network.py", line 94, in __init__
    self._init_graph_network(*args, **kwargs)
  File "/home/vbd667/anaconda3/envs/python36/lib/python3.6/site-packages/keras/engine/network.py", line 241, in _init_graph_network
    self.inputs, self.outputs)
  File "/home/vbd667/anaconda3/envs/python36/lib/python3.6/site-packages/keras/engine/network.py", line 1434, in _map_graph_network
    tensor_index=tensor_index)
  File "/home/vbd667/anaconda3/envs/python36/lib/python3.6/site-packages/keras/engine/network.py", line 1421, in build_map
    node_index, tensor_index)
  File "/home/vbd667/anaconda3/envs/python36/lib/python3.6/site-packages/keras/engine/network.py", line 1421, in build_map
    node_index, tensor_index)
  File "/home/vbd667/anaconda3/envs/python36/lib/python3.6/site-packages/keras/engine/network.py", line 1421, in build_map
    node_index, tensor_index)
  [Previous line repeated 30 more times]
  File "/home/vbd667/anaconda3/envs/python36/lib/python3.6/site-packages/keras/engine/network.py", line 1393, in build_map
    node = layer._inbound_nodes[node_index]
AttributeError: 'NoneType' object has no attribute '_inbound_nodes'
